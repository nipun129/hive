Scenario Based questions:
======================================================================================================================================================================
- Will the reducer work or not if you use “Limit 1” in any HiveQL query?

Depends on the query being executed. For a select query that is executed on Hive which does not include group by, joins, aggregate functions, or complex constraints then 
reducer is not called.So if we are using limit in select query then the reducer would not be Called, it will return the first available row without invoking mapper
and reducers.
======================================================================================================================================================================
- Suppose I have installed Apache Hive on top of my Hadoop cluster using default metastore configuration. Then, what will happen if we have multiple clients trying to
  access Hive at the same time? 
  
Default metastore is the Derby database which only supports 1 user at a time. So if multiple users try to connect at the same time, only 1 will be served at a time.
======================================================================================================================================================================
- Suppose, I create a table that contains details of all the transactions done by the customers: CREATE TABLE transaction_details (cust_id INT, amount FLOAT, 
  month STRING, country STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘,’ ; 
  Now, after inserting 50,000 records in this table, I want to know the total revenue generated for each month. But, Hive is taking too much time in processing this 
  query. How will you solve this problem and list the steps that I will be taking in order to do so?

We can try to solve the large processing time using by partitioning the table by each month. So data will be handled per month for each partition instead of 50000 rows.

Step 1) Create a partitioned table
        CREATE TABLE transaction_details_partitioned (cust_id INT, amount FLOAT, 
        month STRING, country STRING) PARTITIONED BY (month STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘,’ ;
Step 2) Enable dynamic partitionining
        SET hive.exec.dynamic.partition = true;
        SET hive.exec.dynamic.partition.mode = nonstrict;
Step 3) Copy data from the transaction_details table to transaction_details_partitioned table
        INSERT OVERWRITE TABLE transaction_details_partitioned PARTITION(month) SELECT cust_id, amount, month, country FROM transaction_details;
Step 4) Execute the query which we want to perform
======================================================================================================================================================================
- How can you add a new partition for the month December in the above partitioned table?
        ALTER TABLE partitioned_transaction ADD PARTITION (month=’Dec’) LOCATION  ‘/partitioned_transaction’;
======================================================================================================================================================================
- I am inserting data into a table based on partitions dynamically. But, I received an error – FAILED ERROR IN SEMANTIC ANALYSIS: Dynamic partition strict mode 
  requires at least one static partition column. How will you remove this error?

We need to set the below properties
        SET hive.exec.dynamic.partition = true;
        SET hive.exec.dynamic.partition.mode = nonstrict;
======================================================================================================================================================================
- Suppose, I have a CSV file – ‘sample.csv’ present in ‘/temp’ directory with the following entries:
  id first_name last_name email gender ip_address
  How will you consume this CSV file into the Hive warehouse using built-in SerDe?
  
  CREATE TABLE csv_table(id INT, first_name STRING, last_name STRING, email STRING, gender STRING, ip_address STRING)
  ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
  STORED AS TEXTFILE LOCATION ‘/temp’;
  
  Now we can execute queries on this data to perform needed operations.
=======================================================================================================================================================================
- Suppose, I have a lot of small CSV files present in the input directory in HDFS and I want to create a single Hive table corresponding to these files. The data in 
  these files are in the format: {id, name, e-mail, country}. Now, as we know, Hadoop performance degrades when we use lots of small files.
  So, how will you solve this problem where we want to create a single Hive table for lots of small files without degrading the performance of the system?
  
  1) Create a temporary table
  CREATE TABLE temp_table (id INT, name STRING, e-mail STRING, country STRING)
  ROW FORMAT FIELDS DELIMITED TERMINATED BY ‘,’ STORED AS TEXTFILE;
  
  2) Load data into temp_table
  LOAD DATA INPATH '/path' INTO TABLE temp_table;
  
  3) Create a table that will store data in SequenceFile format
  CREATE TABLE sequence_table (id INT, name STRING, e-mail STRING, country STRING)
  ROW FORMAT FIELDS DELIMITED TERMINATED BY ‘,’ STORED AS SEQUENCEFILE;
  
  4) Copy data from temp_table to sequence_table
  INSERT OVERWRITE TABLE sequence_table SELECT * FROM temp_table;
=======================================================================================================================================================================
- LOAD DATA LOCAL INPATH ‘Home/country/state/’
  OVERWRITE INTO TABLE address;

The following statement failed to execute. What can be the cause?

  We should try ro execute as below without LOCAL keyword
  LOAD DATA INPATH ‘Home/country/state/’ OVERWRITE INTO TABLE address;
=======================================================================================================================================================================
- Is it possible to add 100 nodes when we already have 100 nodes in Hive? If yes, how?


======================================================================================================================================================================
Hive Practical questions:

Hive Join operations

Create a  table named CUSTOMERS(ID | NAME | AGE | ADDRESS   | SALARY)
Create a Second  table ORDER(OID | DATE | CUSTOMER_ID | AMOUNT
)

Now perform different joins operations on top of these tables
(Inner JOIN, LEFT OUTER JOIN ,RIGHT OUTER JOIN ,FULL OUTER JOIN)
=======================================================================================================================================================================
BUILD A DATA PIPELINE WITH HIVE

Download a data from the given location - 
https://archive.ics.uci.edu/ml/machine-learning-databases/00360/
=======================================================================================================================================================================
1. Create a hive table as per given schema in your dataset 
CREATE TABLE air_quality_csv (Day STRING, Time STRING, CO_GT DECIMAL, PT08S1_CO INT, NMHC_GT INT, C6H6_GT DECIMAL,
PT08S2_NMHC INT, NOx_GT INT, PT08S3_NOx INT, NO2_GT INT, PT08S4_NO2 INT, PT08S5_O3 INT,T DECIMAL,RH DECIMAL,AH DECIMAL) 
ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘;’ tblproperties ("skip.header.line.count" = "1");
=======================================================================================================================================================================
2. try to place a data into table location
LOAD DATA INPATH '/csv' INTO TABLE air_quality_csv;
=======================================================================================================================================================================
3. Perform a select operation . 
hive> SELECT * FROM air_quality_csv LIMIT 10;
OK
air_quality_csv.day     air_quality_csv.time    air_quality_csv.co_gt   air_quality_csv.pt08s1_co       air_quality_csv.nmhc_gt air_quality_csv.c6h6_gt 
air_quality_csv.pt08s2_nmhcair_quality_csv.nox_gt  air_quality_csv.pt08s3_nox      air_quality_csv.no2_gt  air_quality_csv.pt08s4_no2      air_quality_csv.pt08s5_o3       
air_quality_csv.t       air_quality_csv.rh air_quality_csv.ah
10/03/2004      18.00.00        26      1360    150     119     1046    166     1056    113     1692    1268    136     489     7578
10/03/2004      19.00.00        2       1292    112     94      955     103     1174    92      1559    972     133     477     7255
10/03/2004      20.00.00        22      1402    88      90      939     131     1140    114     1555    1074    119     540     7502
10/03/2004      21.00.00        22      1376    80      92      948     172     1092    122     1584    1203    110     600     7867
10/03/2004      22.00.00        16      1272    51      65      836     131     1205    116     1490    1110    112     596     7888
10/03/2004      23.00.00        12      1197    38      47      750     89      1337    96      1393    949     112     592     7848
11/03/2004      00.00.00        12      1185    31      36      690     62      1462    77      1333    733     113     568     7603
11/03/2004      01.00.00        1       1136    31      33      672     62      1453    76      1333    730     107     600     7702
11/03/2004      02.00.00        9       1094    24      23      609     45      1579    60      1276    620     107     597     7648
11/03/2004      03.00.00        6       1010    19      17      561     -200    1705    -200    1235    501     103     602     7517
=======================================================================================================================================================================
4. Fetch the result of the select operation in your local as a csv file . 
hive> INSERT OVERWRITE LOCAL DIRECTORY '/tmp/air_ooutput.csv'
    > ROW FORMAT DELIMITED
    > FIELDS TERMINATED BY ','
    > SELECT * FROM air_quality_csv;
    
cd /tmp
# ls -lrt
drwxr-xr-x 2 root root 4096 Feb 18 19:36 93090f58-0805-4abc-b4a8-2e41db9d0194_resources
drwxr-xr-x 2 root root 4096 Feb 18 21:59 air_ooutput.csv

Now we can copy the file from Hive docker containier using docker copy using source as the path /tmp/air_oooutput.csv on the container
=======================================================================================================================================================================
5. Perform group by operation . 

hive> SELECT DAY,SUM(CO_GT) FROM air_quality_csv GROUP BY DAY LIMIT 20;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = root_20230218220727_d724204a-fea9-42bc-b1f1-6da79aa51559
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Job running in-process (local Hadoop)
2023-02-18 22:07:29,820 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local1988486518_0002
MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 2957872 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
day     _c1
01/01/2005      291
01/02/2005      688
01/03/2005      245
01/04/2004      576
01/04/2005      -1745
01/05/2004      183
01/06/2004      -380
01/07/2004      483
01/08/2004      218
01/09/2004      438
01/10/2004      -714
01/11/2004      351
01/12/2004      367
02/01/2005      491
02/02/2005      804
02/03/2005      -1568
02/04/2004      318
02/04/2005      205
02/05/2004      152
02/06/2004      -4592
Time taken: 2.291 seconds, Fetched: 20 row(s)
=======================================================================================================================================================================
7. Perform filter operation at least 5 kinds of filter examples . 

hive> SELECT DAY,CO_GT FROM air_quality_csv  WHERE CO_GT > 10 LIMIT 20;;
OK
day     co_gt
10/03/2004      26
10/03/2004      22
10/03/2004      22
10/03/2004      16
10/03/2004      12
11/03/2004      12
11/03/2004      11
11/03/2004      22
11/03/2004      17
11/03/2004      15
11/03/2004      16
11/03/2004      19
11/03/2004      29
11/03/2004      22
11/03/2004      22
11/03/2004      29
11/03/2004      48
11/03/2004      69
11/03/2004      61
11/03/2004      39
Time taken: 0.25 seconds, Fetched: 20 row(s)

hive> SELECT * FROM air_quality WHERE DAY ='2004-03-10';
OK
air_quality.day air_quality.time        air_quality.co_gt       air_quality.pt08s1_co   air_quality.nmhc_gt     air_quality.c6h6_gt     air_quality.pt08s2_nmhc air_quality.nox_gtair_quality.pt08s3_nox   air_quality.no2_gt      air_quality.pt08s4_no2  air_quality.pt08s5_o3   air_quality.t   air_quality.rh  air_quality.ah
2004-03-10      18.00.00        26      1360    150     119     1046    166     1056    113     1692    1268    136     489     7578
2004-03-10      19.00.00        2       1292    112     94      955     103     1174    92      1559    972     133     477     7255
2004-03-10      20.00.00        22      1402    88      90      939     131     1140    114     1555    1074    119     540     7502
2004-03-10      21.00.00        22      1376    80      92      948     172     1092    122     1584    1203    110     600     7867
2004-03-10      22.00.00        16      1272    51      65      836     131     1205    116     1490    1110    112     596     7888
2004-03-10      23.00.00        12      1197    38      47      750     89      1337    96      1393    949     112     592     7848
Time taken: 0.289 seconds, Fetched: 6 row(s)

hive> SELECT * FROM air_quality WHERE DATE(DAY)>='2004-03-10' AND DATE(DAY)<='2004-03-12';
OK
air_quality.day air_quality.time        air_quality.co_gt       air_quality.pt08s1_co   air_quality.nmhc_gt     air_quality.c6h6_gt     air_quality.pt08s2_nmhc air_quality.nox_gtair_quality.pt08s3_nox   air_quality.no2_gt      air_quality.pt08s4_no2  air_quality.pt08s5_o3   air_quality.t   air_quality.rh  air_quality.ah
2004-03-10      18.00.00        26      1360    150     119     1046    166     1056    113     1692    1268    136     489     7578
2004-03-10      19.00.00        2       1292    112     94      955     103     1174    92      1559    972     133     477     7255
2004-03-10      20.00.00        22      1402    88      90      939     131     1140    114     1555    1074    119     540     7502
2004-03-10      21.00.00        22      1376    80      92      948     172     1092    122     1584    1203    110     600     7867
2004-03-10      22.00.00        16      1272    51      65      836     131     1205    116     1490    1110    112     596     7888
2004-03-10      23.00.00        12      1197    38      47      750     89      1337    96      1393    949     112     592     7848
2004-03-11      00.00.00        12      1185    31      36      690     62      1462    77      1333    733     113     568     7603
2004-03-11      01.00.00        1       1136    31      33      672     62      1453    76      1333    730     107     600     7702
2004-03-11      02.00.00        9       1094    24      23      609     45      1579    60      1276    620     107     597     7648
2004-03-11      03.00.00        6       1010    19      17      561     -200    1705    -200    1235    501     103     602     7517
2004-03-11      04.00.00        -200    1011    14      13      527     21      1818    34      1197    445     101     605     7465
2004-03-11      05.00.00        7       1066    8       11      512     16      1918    28      1182    422     110     562     7366

hive> SELECT DAY,PT08S2_NMHC FROM air_quality_csv WHERE PT08S2_NMHC%2=0 LIMIT 50;
OK
day     pt08s2_nmhc
10/03/2004      1046
10/03/2004      948
10/03/2004      836
10/03/2004      750
11/03/2004      690
11/03/2004      672
11/03/2004      512
11/03/2004      900
11/03/2004      960
11/03/2004      762
11/03/2004      774
11/03/2004      1034
11/03/2004      912
11/03/2004      1020
11/03/2004      1488
11/03/2004      1404
11/03/2004      1076
12/03/2004      718
12/03/2004      574
12/03/2004      506
12/03/2004      730
12/03/2004      1236
12/03/2004      1118
12/03/2004      986

hive> SELECT * FROM air_quality WHERE pt08s1_co < 0 LIMIT 20;
OK
air_quality.day air_quality.time        air_quality.co_gt       air_quality.pt08s1_co   air_quality.nmhc_gt     air_quality.c6h6_gt     air_quality.pt08s2_nmhc air_quality.nox_gtair_quality.pt08s3_nox   air_quality.no2_gt      air_quality.pt08s4_no2  air_quality.pt08s5_o3   air_quality.t   air_quality.rh  air_quality.ah
2004-04-01      14.00.00        17      -200    222     -2000   -200    99      -200    72      -200    -200    -200    -200    -200
2004-04-01      15.00.00        19      -200    197     -2000   -200    108     -200    81      -200    -200    -200    -200    -200
2004-04-01      16.00.00        23      -200    319     -2000   -200    131     -200    93      -200    -200    -200    -200    -200
2004-04-08      23.00.00        2       -200    137     -2000   -200    129     -200    106     -200    -200    -200    -200    -200
2004-04-09      00.00.00        24      -200    189     -2000   -200    154     -200    109     -200    -200    -200    -200    -200
2004-04-09      01.00.00        18      -200    159     -2000   -200    118     -200    97      -200    -200    -200    -200    -200
2004-04-09      02.00.00        1       -200    80      -2000   -200    69      -200    83      -200    -200    -200    -200    -200
2004-04-09      03.00.00        1       -200    66      -2000   -200    -200    -200    -200    -200    -200    -200    -200    -200
2004-04-09      04.00.00        1       -200    87      -2000   -200    97      -200    79      -200    -200    -200    -200    -200
2004-04-09      05.00.00        9       -200    79      -2000   -200    145     -200    84      -200    -200    -200    -200    -200
2004-04-09      06.00.00        15      -200    150     -2000   -200    169     -200    86      -200    -200    -200    -200    -200
2004-04-09      07.00.00        26      -200    196     -2000   -200    250     -200    111     -200    -200    -200    -200    -200
2004-04-09      08.00.00        29      -200    299     -2000   -200    215     -200    117     -200    -200    -200    -200    -200
=======================================================================================================================================================================
8. show and example of regex operation
SELECT Day FROM air_quality_csv WHERE Time RLIKE '^[0-9]';

=======================================================================================================================================================================
9. alter table operation 

hive> ALTER TABLE air_quality RENAME TO air_quality_data;
OK
Time taken: 0.315 seconds
=======================================================================================================================================================================
10 . drop table operation
hive> DROP TABLE air_quality_csv;
OK
Time taken: 5.718 seconds
hive>

=======================================================================================================================================================================
12 . order by operation . 
hive> SELECT * FROM air_quality_data ORDER BY DAY LIMIT 50;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = root_20230218223630_146f65ee-66ea-4954-b819-23982b8c1543
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Job running in-process (local Hadoop)
2023-02-18 22:36:32,661 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local869025352_0005
MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 21873416 HDFS Write: 1410124 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
air_quality_data.day    air_quality_data.time   air_quality_data.co_gt  air_quality_data.pt08s1_co      air_quality_data.nmhc_gt        air_quality_data.c6h6_gt        air_quality_data.pt08s2_nmhc       air_quality_data.nox_gt air_quality_data.pt08s3_nox     air_quality_data.no2_gt air_quality_data.pt08s4_no2     air_quality_data.pt08s5_o3      air_quality_data.t air_quality_data.rh     air_quality_data.ah
2004-03-10      18.00.00        26      1360    150     119     1046    166     1056    113     1692    1268    136     489     7578
2004-03-10      21.00.00        22      1376    80      92      948     172     1092    122     1584    1203    110     600     7867
2004-03-10      22.00.00        16      1272    51      65      836     131     1205    116     1490    1110    112     596     7888
2004-03-10      23.00.00        12      1197    38      47      750     89      1337    96      1393    949     112     592     7848
2004-03-10      20.00.00        22      1402    88      90      939     131     1140    114     1555    1074    119     540     7502
2004-03-10      19.00.00        2       1292    112     94      955     103     1174    92      1559    972     133     477     7255
2004-03-11      09.00.00        22      1351    87      95      960     129     1079    101     1583    1028    105     606     7691
2004-03-11      05.00.00        7       1066    8       11      512     16      1918    28      1182    422     110     562     7366
2004-03-11      04.00.00        -200    1011    14      13      527     21      1818    34      1197    445     101     605     7465
2004-03-11      03.00.00        6       1010    19      17      561     -200    1705    -200    1235    501     103     602     7517
2004-03-11      02.00.00        9       1094    24      23      609     45      1579    60      1276    620     107     597     7648
2004-03-11      01.00.00        1       1136    31      33      672     62      1453    76      1333    730     107     600     7702
2004-03-11      08.00.00        2       1333    64      80      900     174     1136    112     1517    1102    108     574     7408
2004-03-11      23.00.00        1       913     26      26      629     47      1565    53      1252    552     82      608     6657
2004-03-11      22.00.00        15      965     61      47      749     94      1325    85      1333    821     82      634     6905
2004-03-11      21.00.00        39      1313    197     128     1076    240     957     136     1707    1285    91      640     7419
=======================================================================================================================================================================
13 . where clause operations you have to perform . 

hive> SELECT * FROM air_quality WHERE DATE(DAY)>='2004-03-10' AND DATE(DAY)<='2004-03-12';
OK
air_quality.day air_quality.time        air_quality.co_gt       air_quality.pt08s1_co   air_quality.nmhc_gt     air_quality.c6h6_gt     air_quality.pt08s2_nmhc air_quality.nox_gtair_quality.pt08s3_nox   air_quality.no2_gt      air_quality.pt08s4_no2  air_quality.pt08s5_o3   air_quality.t   air_quality.rh  air_quality.ah
2004-03-10      18.00.00        26      1360    150     119     1046    166     1056    113     1692    1268    136     489     7578
2004-03-10      19.00.00        2       1292    112     94      955     103     1174    92      1559    972     133     477     7255
2004-03-10      20.00.00        22      1402    88      90      939     131     1140    114     1555    1074    119     540     7502
2004-03-10      21.00.00        22      1376    80      92      948     172     1092    122     1584    1203    110     600     7867
2004-03-10      22.00.00        16      1272    51      65      836     131     1205    116     1490    1110    112     596     7888
2004-03-10      23.00.00        12      1197    38      47      750     89      1337    96      1393    949     112     592     7848
2004-03-11      00.00.00        12      1185    31      36      690     62      1462    77      1333    733     113     568     7603
2004-03-11      01.00.00        1       1136    31      33      672     62      1453    76      1333    730     107     600     7702
2004-03-11      02.00.00        9       1094    24      23      609     45      1579    60      1276    620     107     597     7648
2004-03-11      03.00.00        6       1010    19      17      561     -200    1705    -200    1235    501     103     602     7517
2004-03-11      04.00.00        -200    1011    14      13      527     21      1818    34      1197    445     101     605     7465
2004-03-11      05.00.00        7       1066    8       11      512     16      1918    28      1182    422     110     562     7366
=======================================================================================================================================================================
14 . sorting operation you have to perform . 
hive> SELECT * FROM air_quality_data SORT BY DAY LIMIT 50;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = root_20230218223746_ed6a6db1-ec64-4463-9a6c-28855122229d
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Job running in-process (local Hadoop)
2023-02-18 22:37:51,048 Stage-1 map = 100%,  reduce = 0%
2023-02-18 22:37:52,059 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local764235196_0006
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Job running in-process (local Hadoop)
2023-02-18 22:37:54,799 Stage-2 map = 100%,  reduce = 100%
Ended Job = job_local437179382_0007
MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 23283378 HDFS Write: 1410124 SUCCESS
Stage-Stage-2:  HDFS Read: 23283378 HDFS Write: 1410124 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
air_quality_data.day    air_quality_data.time   air_quality_data.co_gt  air_quality_data.pt08s1_co      air_quality_data.nmhc_gt        air_quality_data.c6h6_gt        air_quality_data.pt08s2_nmhc       air_quality_data.nox_gt air_quality_data.pt08s3_nox     air_quality_data.no2_gt air_quality_data.pt08s4_no2     air_quality_data.pt08s5_o3      air_quality_data.t air_quality_data.rh     air_quality_data.ah
2004-03-10      18.00.00        26      1360    150     119     1046    166     1056    113     1692    1268    136     489     7578
2004-03-10      23.00.00        12      1197    38      47      750     89      1337    96      1393    949     112     592     7848
2004-03-10      20.00.00        22      1402    88      90      939     131     1140    114     1555    1074    119     540     7502
2004-03-10      19.00.00        2       1292    112     94      955     103     1174    92      1559    972     133     477     7255
2004-03-10      22.00.00        16      1272    51      65      836     131     1205    116     1490    1110    112     596     7888
2004-03-10      21.00.00        22      1376    80      92      948     172     1092    122     1584    1203    110     600     7867
2004-03-11      21.00.00        39      1313    197     128     1076    240     957     136     1707    1285    91      640     7419
2004-03-11      01.00.00        1       1136    31      33      672     62      1453    76      1333    730     107     600     7702
2004-03-11      02.00.00        9       1094    24      23      609     45      1579    60      1276    620     107     597     7648
2004-03-11      03.00.00        6       1010    19      17      561     -200    1705    -200    1235    501     103     602     7517
=======================================================================================================================================================================
15 . distinct operation you have to perform . 

hive> SELECT DISTINCT DAY FROM air_quality_data LIMIT 50;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = root_20230218223847_9382b38b-a6e0-4d1a-b1f4-178c503fa430
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Job running in-process (local Hadoop)
2023-02-18 22:38:49,112 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local693906642_0009
MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 26103302 HDFS Write: 1410124 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
day
2004-03-10
2004-03-11
2004-03-12
2004-03-13
2004-03-14
2004-03-15
2004-03-16
2004-03-17
2004-03-18
2004-03-19
2004-03-20
2004-03-21
2004-03-22
2004-03-23
2004-03-24
2004-03-25
2004-03-26
=======================================================================================================================================================================
16 . like an operation you have to perform . 
hive> SELECT * FROM air_quality_csv WHERE Day LIKE '%2004' LIMIT 20;
OK
air_quality_csv.day     air_quality_csv.time    air_quality_csv.co_gt   air_quality_csv.pt08s1_co       air_quality_csv.nmhc_gt air_quality_csv.c6h6_gt air_quality_csv.pt08s2_nmhcair_quality_csv.nox_gt  air_quality_csv.pt08s3_nox      air_quality_csv.no2_gt  air_quality_csv.pt08s4_no2      air_quality_csv.pt08s5_o3       air_quality_csv.t       air_quality_csv.rh air_quality_csv.ah
10/03/2004      18.00.00        26      1360    150     119     1046    166     1056    113     1692    1268    136     489     7578
10/03/2004      19.00.00        2       1292    112     94      955     103     1174    92      1559    972     133     477     7255
10/03/2004      20.00.00        22      1402    88      90      939     131     1140    114     1555    1074    119     540     7502
10/03/2004      21.00.00        22      1376    80      92      948     172     1092    122     1584    1203    110     600     7867
10/03/2004      22.00.00        16      1272    51      65      836     131     1205    116     1490    1110    112     596     7888
10/03/2004      23.00.00        12      1197    38      47      750     89      1337    96      1393    949     112     592     7848
11/03/2004      00.00.00        12      1185    31      36      690     62      1462    77      1333    733     113     568     7603
11/03/2004      01.00.00        1       1136    31      33      672     62      1453    76      1333    730     107     600     7702
11/03/2004      02.00.00        9       1094    24      23      609     45      1579    60      1276    620     107     597     7648
11/03/2004      03.00.00        6       1010    19      17      561     -200    1705    -200    1235    501     103     602     7517
11/03/2004      04.00.00        -200    1011    14      13      527     21      1818    34      1197    445     101     605     7465
11/03/2004      05.00.00        7       1066    8       11      512     16      1918    28      1182    422     110     562     7366
11/03/2004      06.00.00        7       1052    16      16      553     34      1738    48      1221    472     105     581     7353
11/03/2004      07.00.00        11      1144    29      32      667     98      1490    82      1339    730     102     596     7417
11/03/2004      08.00.00        2       1333    64      80      900     174     1136    112     1517    1102    108     574     7408
11/03/2004      09.00.00        22      1351    87      95      960     129     1079    101     1583    1028    105     606     7691
11/03/2004      10.00.00        17      1233    77      63      827     112     1218    98      1446    860     108     584     7552
11/03/2004      11.00.00        15      1179    43      50      762     95      1328    92      1362    671     105     579     7352
11/03/2004      12.00.00        16      1236    61      52      774     104     1301    95      1401    664     95      668     7951
11/03/2004      13.00.00        19      1286    63      73      869     146     1162    112     1537    799     83      764     8393
Time taken: 0.303 seconds, Fetched: 20 row(s)

=======================================================================================================================================================================
17 . union operation you have to perform . 

hive> SELECT * FROM air_quality_data WHERE DATE(DAY)>='2004-03-10'
    > UNION
    > SELECT * FROM air_quality_data WHERE DATE(DAY)<='2004-03-12' LIMIT 20;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = root_20230218224450_0b468014-0fad-4d20-816b-f97f4bc4dda4
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Job running in-process (local Hadoop)
2023-02-18 22:44:52,574 Stage-1 map = 0%,  reduce = 0%
2023-02-18 22:44:53,586 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local971411992_0012
MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 30333188 HDFS Write: 1410124 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
OK
_u2.day _u2.time        _u2.co_gt       _u2.pt08s1_co   _u2.nmhc_gt     _u2.c6h6_gt     _u2.pt08s2_nmhc _u2.nox_gt      _u2.pt08s3_nox  _u2.no2_gt      _u2.pt08s4_no2  _u2.pt08s5_o3      _u2.t   _u2.rh  _u2.ah
2004-03-10      18.00.00        26      1360    150     119     1046    166     1056    113     1692    1268    136     489     7578
2004-03-10      19.00.00        2       1292    112     94      955     103     1174    92      1559    972     133     477     7255
2004-03-10      20.00.00        22      1402    88      90      939     131     1140    114     1555    1074    119     540     7502
2004-03-10      21.00.00        22      1376    80      92      948     172     1092    122     1584    1203    110     600     7867
2004-03-10      22.00.00        16      1272    51      65      836     131     1205    116     1490    1110    112     596     7888
=======================================================================================================================================================================
18 . table view operation you have to perform . 

hive> SHOW TABLES
    > ;
OK
tab_name
air_quality_csv
Time taken: 0.072 seconds, Fetched: 1 row(s)

=======================================================================================================================================================================
hive operation with python

Create a python application that connects to the Hive database for extracting data, creating sub tables for data processing, drops temporary tables.fetch rows to 
python itself into a list of tuples and mimic the join or filter operations
